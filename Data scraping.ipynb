{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b6b84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import datetime\n",
    "\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import requests\n",
    "import glob\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e505baf",
   "metadata": {},
   "source": [
    "# 1. Weather data: \n",
    "\n",
    "Source: [Deutscher Wetter Dienst (German Weather Service)](https://www.dwd.de/DE/Home/home_node.html)\n",
    "\n",
    "[Python API](https://wetterdienst.readthedocs.io/en/latest/overview.html), \n",
    "[Rest API](https://dwd.api.bund.dev/)\n",
    "\n",
    "More information about the data can be found [here](https://www.dwd.de/DE/Home/home_node.html;jsessionid=5F6860A891AB172540563F2A56F045B3.live31092)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65e67277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wetterdienst import Wetterdienst\n",
    "from wetterdienst.provider.dwd.observation import DwdObservationRequest, DwdObservationDataset, DwdObservationPeriod, DwdObservationResolution\n",
    "\n",
    "# Create API instance\n",
    "API = Wetterdienst(provider=\"dwd\", network=\"observation\")\n",
    "\n",
    "# Create request\n",
    "request = DwdObservationRequest(\n",
    "    parameter=[DwdObservationDataset.SOLAR, DwdObservationDataset.WIND],\n",
    "    resolution=DwdObservationResolution.HOURLY,\n",
    "    start_date=datetime.datetime(2015, 1, 1),\n",
    "    end_date=datetime.datetime(2023, 11, 19),\n",
    "    #period=DwdObservationPeriod.HISTORICAL,\n",
    ")\n",
    "\n",
    "# Create df for available stations\n",
    "d_stations = request.all().df.to_pandas()\n",
    "d_stations = d_stations[['station_id', 'state', 'name']]\n",
    "\n",
    "# Parameters that should be fetched\n",
    "parameters = ['wind_speed', 'sunshine_duration', 'radiation_global']\n",
    "\n",
    "# Print parameters that are available with hourly resolution\n",
    "DwdObservationRequest.discover()['hourly'];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b59ccd72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8366bf3c30140338d1a7306f6840e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/446 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m state \u001b[38;5;241m=\u001b[39m d_stations[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m][idx]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# do actual query\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m d\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mquery():\n\u001b[1;32m     13\u001b[0m     d \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlbasic/lib/python3.10/site-packages/wetterdienst/core/timeseries/values.py:392\u001b[0m, in \u001b[0;36mTimeseriesValues.query\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m station_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parameter, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msr\u001b[38;5;241m.\u001b[39mparameter:\n\u001b[0;32m--> 392\u001b[0m     parameter_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collect_station_parameter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstation_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parameter_df\u001b[38;5;241m.\u001b[39mis_empty():\n\u001b[1;32m    397\u001b[0m         parameter_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_empty_station_parameter_df(station_id\u001b[38;5;241m=\u001b[39mstation_id, dataset\u001b[38;5;241m=\u001b[39mdataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlbasic/lib/python3.10/site-packages/wetterdienst/provider/dwd/observation/api.py:160\u001b[0m, in \u001b[0;36mDwdObservationValues._collect_station_parameter\u001b[0;34m(self, station_id, parameter, dataset)\u001b[0m\n\u001b[1;32m    157\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameter_identifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Station will be skipped.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m filenames_and_files \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_climate_observations_data_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m period_df \u001b[38;5;241m=\u001b[39m parse_climate_observations_data(filenames_and_files, dataset, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msr\u001b[38;5;241m.\u001b[39mresolution, period)\n\u001b[1;32m    164\u001b[0m parameter_data\u001b[38;5;241m.\u001b[39mappend(period_df)\n",
      "File \u001b[0;32m~/anaconda3/envs/mlbasic/lib/python3.10/site-packages/wetterdienst/provider/dwd/observation/download.py:28\u001b[0m, in \u001b[0;36mdownload_climate_observations_data_parallel\u001b[0;34m(remote_files, settings)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_climate_observations_data_parallel\u001b[39m(\n\u001b[1;32m     20\u001b[0m     remote_files: pl\u001b[38;5;241m.\u001b[39mSeries, settings: Settings\n\u001b[1;32m     21\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[\u001b[38;5;28mstr\u001b[39m, BytesIO]]:\n\u001b[1;32m     22\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m    Wrapper for ``_download_dwd_data`` to provide a multiprocessing feature.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    :param remote_files:    List of requested files\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m    :return:                List of downloaded files\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[1;32m     29\u001b[0m         files_in_bytes \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mmap(partial(_download_climate_observations_data, settings\u001b[38;5;241m=\u001b[39msettings), remote_files)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(remote_files, files_in_bytes))\n",
      "File \u001b[0;32m~/anaconda3/envs/mlbasic/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlbasic/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlbasic/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/mlbasic/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fetch_data = True\n",
    "if fetch_data:\n",
    "    # Loop through all stations and add values for all parameters to dictionary\n",
    "    # Structure of dictionary: key: parameter_state (i.e. wind_speed_Berlin)\n",
    "    # Note: For each key, values are 2d since there are multiple stations per state\n",
    "    data = {}\n",
    "    for idx in tqdm(range(len(d_stations))):\n",
    "        d = request.filter_by_station_id(station_id=(d_stations['station_id'][idx], ))\n",
    "        state = d_stations['state'][idx]\n",
    "\n",
    "        # do actual query\n",
    "        for result in d.values.query():\n",
    "            d = result.df.to_pandas()\n",
    "        if idx==0:\n",
    "            date = d['date'][d['parameter']=='end_of_interval']\n",
    "            data['time_unix'] = [dt.timestamp() for dt in list(date)]\n",
    "        \n",
    "        # Get values for each parameter\n",
    "        for param in parameters:\n",
    "            values = d[d['parameter']==param]['value']\n",
    "            if sum(values.isna())<0.2*len(values):\n",
    "                if not state==None:\n",
    "                    column_name = param+'_'+state\n",
    "                    if column_name in data:\n",
    "                        data[column_name].append(list(values))\n",
    "                    else:\n",
    "                        data[column_name] = [list(values)]\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878a471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "for key in list(df.keys()):\n",
    "    #print(key)\n",
    "    df[key] = np.nanmean(df[key], axis=0)\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df['time_unix'] = data['time_unix']\n",
    "df.to_csv('Weather_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c00ff6",
   "metadata": {},
   "source": [
    "# 2. Energy data: \n",
    "\n",
    "Source: [Energy-charts.info](https://energy-charts.info/)\n",
    "\n",
    "[Rest API](https://api.energy-charts.info/)\n",
    "Here, I collect 'public_power', note that this does not include power produced for industrial self supply\n",
    "\n",
    "The website is maintained by Fraunhofer Institute for Solar Energy Systems (ISE) a German organization for applied research.\n",
    "ISE collects data from both federal agencies and private companies, see [here](https://energy-charts.info/sources.html?l=en&c=DE\n",
    ") for more information \n",
    "\n",
    "Further information about the different categories of power production can be found [here](https://energy-charts.info/explanations.html?l=en&c=DE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70fb97e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "69.57104015350342\n"
     ]
    }
   ],
   "source": [
    "# Format: YYYY-MM-DD\n",
    "date_start = '2015-01-01'\n",
    "date_end = '2023-11-20'\n",
    "\n",
    "# 'de' for Germany\n",
    "country_code = 'de'\n",
    "\n",
    "# Get request\n",
    "t0 = time.time()\n",
    "response = requests.get(f'https://api.energy-charts.info/public_power?country={country_code}&start={date_start}T00%3A00%2B01%3A00&end={date_end}T23%3A45%2B01%3A00')\n",
    "print(response)\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c32d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from response and convert to pandas df\n",
    "data = {}\n",
    "t = response.json()['unix_seconds']\n",
    "data.update({'time_unix':t})\n",
    "for elem in response.json()['production_types']:\n",
    "    data.update({elem['name']: elem['data']})\n",
    "        \n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save df as csv\n",
    "df.to_csv('Energy_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e844d8",
   "metadata": {},
   "source": [
    "# Combine and modify data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14cffc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_abr(state):\n",
    "    d={\n",
    "    'Baden-Württemberg':'BW',\n",
    "    'Bayern':'BY',\n",
    "    'Berlin':'BE',\n",
    "    'Brandenburg':'BB',\n",
    "    'Bremen':'HB',\n",
    "    'Hamburg':'HH',\n",
    "    'Hessen':'HE',\n",
    "    'Mecklenburg-Vorpommern':'MV',\n",
    "    'Niedersachsen':'NI',\n",
    "    'Nordrhein-Westfalen':'NW',\n",
    "    'Rheinland-Pfalz':'RP',\n",
    "    'Saarland':'SL',\n",
    "    'Sachsen':'SN',\n",
    "    'Sachsen-Anhalt':'ST',\n",
    "    'Schleswig-Holstein':'SH',\n",
    "    'Thüringen':'TH'}\n",
    "    return d[state]\n",
    "\n",
    "# Import weather data\n",
    "df_weather = pd.read_csv('Weather_data.csv')\n",
    "df_weather['date_time'] = df_weather['time_unix'].apply(datetime.datetime.fromtimestamp).dt.strftime('%Y-%m-%d-%H')\n",
    "df_weather = df_weather.drop(['time_unix', 'Unnamed: 0'], axis='columns')\n",
    "df_weather = df_weather.set_index('date_time')\n",
    "\n",
    "def rename(string):\n",
    "    state = string.split('_')[-1]\n",
    "    old_key = string.split('_')[0]+'_'+string.split('_')[1]\n",
    "    new_key = old_key+'_'+get_state_abr(state)  \n",
    "    return new_key\n",
    "\n",
    "df_weather = df_weather.rename(rename, axis='columns')\n",
    "\n",
    "# Import energy data\n",
    "df_energy = pd.read_csv('Energy_data.csv')\n",
    "df_energy['date_time'] = df_energy['time_unix'].apply(datetime.datetime.fromtimestamp).dt.strftime('%Y-%m-%d-%H')\n",
    "df_energy.set_index('date_time')\n",
    "df_energy = df_energy.drop(['time_unix', 'Unnamed: 0'], axis='columns')\n",
    "df_energy = df_energy.groupby('date_time').mean()\n",
    "\n",
    "# Joine data frames along date_time column, create some extra features\n",
    "df = df_energy.join(df_weather)\n",
    "df['date_time'] = df.index\n",
    "df['date_time'] = df['date_time'].apply(lambda string : datetime.datetime.strptime(string, '%Y-%m-%d-%H'))\n",
    "df['year'] = df['date_time'].dt.year\n",
    "df['month'] = df['date_time'].dt.month\n",
    "df['day'] = df['date_time'].dt.weekday\n",
    "df['date_year'] = df['date_time'].dt.strftime('%Y-%m-%d')\n",
    "df['hour'] = df['date_time'].dt.strftime('%H')\n",
    "df['date'] = df['date_time'].dt.strftime('%m-%d')\n",
    "df = df.drop('date_time', axis='columns')\n",
    "\n",
    "# Replace None values by median\n",
    "for key in df.select_dtypes(include=np.number):\n",
    "    df[key] = df[key].fillna(np.nanmedian(df[key]))\n",
    "\n",
    "df.to_csv('Energy_production_weather.csv')\n",
    "os.remove('Weather_data.csv')\n",
    "os.remove('Energy_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d60ac87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe25dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
